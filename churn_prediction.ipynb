{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPO11+cif91xI0l7b6KE5hP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inbalv/tictactoe/blob/master/churn_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. User Demographics and Acquisition Data\n",
        "User Demographics:\n",
        "• Age, gender, location, language, and other available profile information.\n",
        "\n",
        "# Acquisition Details:\n",
        "• Acquisition channel (e.g., organic, paid, referral), campaign identifier, signup date/time, and initial user segment.\n",
        "\n",
        "# 2. Behavioral Metrics\n",
        "Usage Frequency:\n",
        "• Number of sessions per day/week, average session frequency over a set period.\n",
        "\n",
        "# Session Duration:\n",
        "• Average session length and distribution of session durations.\n",
        "\n",
        "# Recency:\n",
        "• Time elapsed since the last session or interaction.\n",
        "\n",
        "# Engagement Patterns:\n",
        "• Time between sessions, consistency of usage (e.g., variance in daily or weekly activity).\n",
        "\n",
        "# 3. In-App Engagement Features\n",
        "Feature-Specific Interactions:\n",
        "• Counts of interactions with key app features (e.g., tutorial completions, level-ups, social interactions, or game-specific actions).\n",
        "\n",
        "# Event Metrics:\n",
        "• Number of specific in-app events (e.g., clicks, swipes, achievements) that correlate with engagement.\n",
        "\n",
        "# Conversion Events:\n",
        "• Occurrence of meaningful actions (e.g., in-app purchases, ad clicks) if applicable.\n",
        "\n",
        "# 4. Device and Technical Attributes\n",
        "Device Information:\n",
        "• Device type (mobile, tablet), operating system, app version, and hardware specifications.\n",
        "\n",
        "# Technical Performance:\n",
        "• App load times, crash logs, and error frequencies that might affect user experience.\n",
        "\n",
        "5. Temporal and Contextual Features\n",
        "Time-Related Patterns:\n",
        "• Day of week or time of day usage trends, seasonality effects, and changes in user behavior around specific events or promotions.\n",
        "\n",
        "# Environmental Context:\n",
        "• External factors like network conditions or concurrent marketing campaigns.\n",
        "\n",
        "# 6. Additional Behavioral and Social Indicators\n",
        "Social Interactions:\n",
        "• In-app messaging, friend referrals, or interactions with community features.\n",
        "\n",
        "# Support Engagement:\n",
        "• Frequency of customer support contacts or reported issues, which can be an early indicator of dissatisfaction.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8uUeztbixJrI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "features list :\n",
        "\n",
        " age, location, language, country , device_type(phone, tablet), os, device_pos(vertical or horizontl) , is_cc_inapp,  Acquisition_type(organic, referral, paid), campain_id, sign_up_date,\n",
        "n_sessions_per_day, n_sessions_week, average_session_length, std_session_durations, time_since_last_session, social_interactions, playing_with_friends, playing_with_close_friends, friend_leaving, , average_time_between_weekly_sessions, total_in_app_purchases, clicks_events,seasonality(morning, evenings, weekends), n_tutorial_completions, level_in_game, special_points, special_gifts, achievements, app_rank, app_review.\n"
      ],
      "metadata": {
        "id": "GwIMuXkaxcFX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scpcoW3wtpI7"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "\n",
        "def label_churn(df: pd.DataFrame, last_active_col: str, threshold_days: int = 30, ref_date: str = None) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Labels users as churned if the number of days since their last activity exceeds a threshold.\n",
        "\n",
        "    Parameters:\n",
        "        df (pd.DataFrame): DataFrame containing user activity data.\n",
        "        last_active_col (str): Name of the column with last active dates.\n",
        "        threshold_days (int, optional): Number of days without activity after which a user is considered churned. Defaults to 30.\n",
        "        ref_date (str, optional): Reference date in 'YYYY-MM-DD' format. If None, the max date in last_active_col is used.\n",
        "\n",
        "    Returns:\n",
        "        pd.DataFrame: A copy of the DataFrame with two new columns:\n",
        "                      - 'days_since_last_active': Number of days since the user was last active.\n",
        "                      - 'churn': Binary flag (1 for churned, 0 for active).\n",
        "    \"\"\"\n",
        "    # Ensure the date column is in datetime format\n",
        "    df[last_active_col] = pd.to_datetime(df[last_active_col])\n",
        "\n",
        "    # Determine the reference date (defaults to the most recent date in the data)\n",
        "    if ref_date is None:\n",
        "        ref_date_dt = df[last_active_col].max()\n",
        "    else:\n",
        "        ref_date_dt = pd.to_datetime(ref_date)\n",
        "\n",
        "    # Calculate days since last active\n",
        "    df['days_since_last_active'] = (ref_date_dt - df[last_active_col]).dt.days\n",
        "\n",
        "    # Label churn: 1 if the days since last active exceed the threshold, otherwise 0\n",
        "    df['churn'] = np.where(df['days_since_last_active'] > threshold_days, 1, 0)\n",
        "\n",
        "    return df\n",
        "\n",
        "def evaluate_churn_model(y_true, y_pred, y_prob):\n",
        "    \"\"\"\n",
        "    Evaluates the performance of a churn classification model.\n",
        "\n",
        "    Parameters:\n",
        "        y_true (array-like): True binary labels (0 for active, 1 for churned).\n",
        "        y_pred (array-like): Predicted binary labels.\n",
        "        y_prob (array-like): Predicted probabilities for the positive class (churn).\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing the following evaluation metrics:\n",
        "              - accuracy\n",
        "              - precision\n",
        "              - recall\n",
        "              - f1_score\n",
        "              - roc_auc\n",
        "    \"\"\"\n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'precision': precision_score(y_true, y_pred),\n",
        "        'recall': recall_score(y_true, y_pred),\n",
        "        'f1_score': f1_score(y_true, y_pred),\n",
        "        'roc_auc': roc_auc_score(y_true, y_prob)\n",
        "    }\n",
        "    return metrics\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Create a sample dataset\n",
        "    data = {\n",
        "        'user_id': [1, 2, 3, 4],\n",
        "        'last_active_date': ['2025-03-01', '2025-03-15', '2025-04-01', '2025-02-28']\n",
        "    }\n",
        "    df_users = pd.DataFrame(data)\n",
        "\n",
        "    # Label churn using a threshold of 30 days\n",
        "    df_labeled = label_churn(df_users, last_active_col='last_active_date', threshold_days=30, ref_date='2025-04-15')\n",
        "    print(df_labeled)\n",
        "\n",
        "    # Suppose these are the model predictions for demonstration\n",
        "    y_true = [0, 0, 0, 1]  # Actual labels\n",
        "    y_pred = [0, 1, 0, 1]  # Predicted labels\n",
        "    y_prob = [0.2, 0.7, 0.1, 0.9]  # Predicted probabilities for churn\n",
        "\n",
        "    # Evaluate model performance\n",
        "    metrics = evaluate_churn_model(y_true, y_pred, y_prob)\n",
        "    print(metrics)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1. User Demographics and Acquisition Data\n",
        "User Demographics:\n",
        "• Age, gender, location, language, and other available profile information.\n",
        "\n",
        "Acquisition Details:\n",
        "• Acquisition channel (e.g., organic, paid, referral), campaign identifier, signup date/time, and initial user segment.\n",
        "\n",
        "2. Behavioral Metrics\n",
        "Usage Frequency:\n",
        "• Number of sessions per day/week, average session frequency over a set period.\n",
        "\n",
        "Session Duration:\n",
        "• Average session length and distribution of session durations.\n",
        "\n",
        "Recency:\n",
        "• Time elapsed since the last session or interaction.\n",
        "\n",
        "Engagement Patterns:\n",
        "• Time between sessions, consistency of usage (e.g., variance in daily or weekly activity).\n",
        "\n",
        "3. In-App Engagement Features\n",
        "Feature-Specific Interactions:\n",
        "• Counts of interactions with key app features (e.g., tutorial completions, level-ups, social interactions, or game-specific actions).\n",
        "\n",
        "Event Metrics:\n",
        "• Number of specific in-app events (e.g., clicks, swipes, achievements) that correlate with engagement.\n",
        "\n",
        "Conversion Events:\n",
        "• Occurrence of meaningful actions (e.g., in-app purchases, ad clicks) if applicable.\n",
        "\n",
        "4. Device and Technical Attributes\n",
        "Device Information:\n",
        "• Device type (mobile, tablet), operating system, app version, and hardware specifications.\n",
        "\n",
        "Technical Performance:\n",
        "• App load times, crash logs, and error frequencies that might affect user experience.\n",
        "\n",
        "5. Temporal and Contextual Features\n",
        "Time-Related Patterns:\n",
        "• Day of week or time of day usage trends, seasonality effects, and changes in user behavior around specific events or promotions.\n",
        "\n",
        "Environmental Context:\n",
        "• External factors like network conditions or concurrent marketing campaigns.\n",
        "\n",
        "6. Additional Behavioral and Social Indicators\n",
        "Social Interactions:\n",
        "• In-app messaging, friend referrals, or interactions with community features.\n",
        "\n",
        "Support Engagement:\n",
        "• Frequency of customer support contacts or reported issues, which can be an early indicator of dissatisfaction."
      ],
      "metadata": {
        "id": "rpbOFGraxHrO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "def count_events_before_session(df, user_col=\"user_id\", time_col=\"event_time\", event_type_col=\"event_type\"):\n",
        "    \"\"\"\n",
        "    For each event, computes a cumulative count of events per user ordered by event_time.\n",
        "    Then, for session start events, calculates the number of events that occurred before that session.\n",
        "\n",
        "    Parameters:\n",
        "        df (DataFrame): Input Spark DataFrame with event records.\n",
        "        user_col (str): Column name representing the user. Defaults to \"user_id\".\n",
        "        time_col (str): Column name containing the event timestamp. Defaults to \"event_time\".\n",
        "        event_type_col (str): Column name representing the event type. Defaults to \"event_type\".\n",
        "        session_value (str): The value in event_type_col that indicates a session start. Defaults to \"session_start\".\n",
        "\n",
        "    Returns:\n",
        "        DataFrame: The original DataFrame with two additional columns:\n",
        "                   - 'cum_count': Cumulative count of events per user.\n",
        "                   - 'events_before_session': For session start events, the count of events that occurred prior to that session.\n",
        "                     For non-session events, this column will be null.\n",
        "    \"\"\"\n",
        "    # Define a window partitioned by user and ordered by event_time\n",
        "    window_spec = Window.partitionBy(user_col,event_type_col).orderBy(F.col(time_col))\n",
        "\n",
        "    # Compute the cumulative count of events for each user\n",
        "    df_with_cum = df.withColumn(\"cum_count\", F.count(\"*\").over(window_spec) - 1)\n",
        "\n",
        "\n",
        "    return df_with_events_before\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u0AXvpogBSne"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession, functions as F\n",
        "from pyspark.sql.window import Window\n",
        "from functools import reduce\n",
        "from pyspark.sql import DataFrame\n",
        "\n",
        "# Create a Spark session\n",
        "spark = SparkSession.builder.appName(\"FeatureEngineering\").getOrCreate()\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Example: Base User Data (Demographics, Device, Acquisition, etc.)\n",
        "# -----------------------------------------------------------------------------\n",
        "data_users = [\n",
        "    # user_id, age, location, language, country, device_type, os, device_pos, is_cc_inapp, acquisition_type, campaign_id, sign_up_date, app_rank, app_review\n",
        "    (1, 25, \"New York\", \"English\", \"USA\", \"phone\", \"iOS\", \"vertical\", True, \"organic\", \"camp1\", \"2021-01-01\", 10, 4.5),\n",
        "    (2, 30, \"Los Angeles\", \"English\", \"USA\", \"tablet\", \"Android\", \"horizontal\", False, \"paid\", \"camp2\", \"2021-02-01\", 8, 4.2)\n",
        "]\n",
        "columns_users = [\"user_id\", \"age\", \"location\", \"language\", \"country\", \"device_type\", \"os\", \"device_pos\",\n",
        "                 \"is_cc_inapp\", \"acquisition_type\", \"campaign_id\", \"sign_up_date\", \"app_rank\", \"app_review\"]\n",
        "\n",
        "df_users = spark.createDataFrame(data_users, columns_users)\n",
        "df_users = df_users.withColumn(\"sign_up_date\", F.to_date(\"sign_up_date\", \"yyyy-MM-dd\"))\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Example: Raw Event Data (Session, Clicks, Purchases, Social, etc.)\n",
        "# -----------------------------------------------------------------------------\n",
        "# For simplicity, we assume that the events dataframe contains a column 'event_time' (timestamp),\n",
        "# 'event_type' (string identifying the type), and additional columns when needed.\n",
        "data_events = [\n",
        "    # user_id, event_time, event_type, session_start_time, session_end_time, points, level\n",
        "    (1, \"2021-03-01 10:00:00\", \"session_start\", \"2021-03-01 10:00:00\", \"2021-03-01 10:30:00\", None, None),\n",
        "    (1, \"2021-03-01 10:05:00\", \"click\", None, None, None, None),\n",
        "    (1, \"2021-03-01 11:00:00\", \"session_start\", \"2021-03-01 11:00:00\", \"2021-03-01 11:25:00\", None, None),\n",
        "    (1, \"2021-03-01 11:30:00\", \"social_interaction\", None, None, None, None),\n",
        "    (1, \"2021-03-01 12:00:00\", \"tutorial_completion\", None, None, None, None),\n",
        "    (2, \"2021-03-02 09:00:00\", \"session_start\", \"2021-03-02 09:00:00\", \"2021-03-02 09:45:00\", None, None),\n",
        "    (2, \"2021-03-02 09:50:00\", \"in_app_purchase\", None, None, None, None),\n",
        "    (2, \"2021-03-02 10:15:00\", \"session_start\", \"2021-03-02 10:15:00\", \"2021-03-02 10:35:00\", None, None),\n",
        "    (2, \"2021-03-02 10:40:00\", \"tutorial_completion\", None, None, None, None)\n",
        "]\n",
        "columns_events = [\"user_id\", \"event_time\", \"event_type\", \"session_start_time\", \"session_end_time\", \"points\", \"level\"]\n",
        "df_events = spark.createDataFrame(data_events, columns_events)\n",
        "df_events = df_events.withColumn(\"event_time\", F.to_timestamp(\"event_time\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "df_events = df_events.withColumn(\"session_start_time\", F.to_timestamp(\"session_start_time\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "df_events = df_events.withColumn(\"session_end_time\", F.to_timestamp(\"session_end_time\", \"yyyy-MM-dd HH:mm:ss\"))\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Feature Engineering: Event-Based Aggregations\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# (A) Sessions-Related Features ------------------------------------------------\n",
        "\n",
        "# Filter session start events\n",
        "df_sessions = df_events.filter(F.col(\"event_type\") == \"session_start\")\n",
        "df_sessions = df_sessions.withColumn(\"session_date\", F.to_date(\"event_time\"))\n",
        "df_sessions = df_sessions.withColumn(\"session_week\", F.weekofyear(\"session_date\"))\n",
        "\n",
        "# 1. Average sessions per day\n",
        "sessions_per_day = df_sessions.groupBy(\"user_id\", \"session_date\") \\\n",
        "                              .agg(F.count(\"*\").alias(\"sessions_count\"))\n",
        "avg_sessions_per_day = sessions_per_day.groupBy(\"user_id\") \\\n",
        "                                       .agg(F.avg(\"sessions_count\").alias(\"n_sessions_per_day\"))\n",
        "\n",
        "# 2. Average sessions per week\n",
        "sessions_per_week = df_sessions.groupBy(\"user_id\", \"session_week\") \\\n",
        "                               .agg(F.count(\"*\").alias(\"sessions_count\"))\n",
        "avg_sessions_per_week = sessions_per_week.groupBy(\"user_id\") \\\n",
        "                                         .agg(F.avg(\"sessions_count\").alias(\"n_sessions_week\"))\n",
        "\n",
        "# 3. Average and standard deviation of session lengths\n",
        "df_sessions = df_sessions.withColumn(\"session_length\",\n",
        "                                     F.unix_timestamp(\"session_end_time\") - F.unix_timestamp(\"session_start_time\"))\n",
        "session_length_stats = df_sessions.groupBy(\"user_id\") \\\n",
        "                                  .agg(F.avg(\"session_length\").alias(\"average_session_length\"),\n",
        "                                       F.stddev(\"session_length\").alias(\"std_session_durations\"))\n",
        "\n",
        "# 4. Time since last session (in seconds)\n",
        "last_session = df_sessions.groupBy(\"user_id\") \\\n",
        "                          .agg(F.max(\"event_time\").alias(\"last_session_time\"))\n",
        "last_session = last_session.withColumn(\"time_since_last_session\",\n",
        "                                       F.unix_timestamp(F.current_timestamp()) - F.unix_timestamp(\"last_session_time\"))\n",
        "\n",
        "# 5. Average time between sessions per user\n",
        "window_spec = Window.partitionBy(\"user_id\").orderBy(\"event_time\")\n",
        "df_sessions = df_sessions.withColumn(\"prev_session_time\", F.lag(\"event_time\").over(window_spec))\n",
        "df_sessions = df_sessions.withColumn(\"time_diff\",\n",
        "                                     F.unix_timestamp(\"event_time\") - F.unix_timestamp(\"prev_session_time\"))\n",
        "avg_time_between_sessions = df_sessions.groupBy(\"user_id\") \\\n",
        "                                       .agg(F.avg(\"time_diff\").alias(\"average_time_between_weekly_sessions\"))\n",
        "\n",
        "# (B) Other Event-Based Features -----------------------------------------------\n",
        "\n",
        "# 6. Social interactions\n",
        "social_interactions = df_events.filter(F.col(\"event_type\") == \"social_interaction\") \\\n",
        "                               .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"social_interactions\"))\n",
        "\n",
        "# 7. Playing with friends (assuming event_type indicates such events)\n",
        "playing_with_friends = df_events.filter(F.col(\"event_type\") == \"playing_with_friends\") \\\n",
        "                                .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"playing_with_friends\"))\n",
        "\n",
        "# 8. Playing with close friends\n",
        "playing_with_close_friends = df_events.filter(F.col(\"event_type\") == \"playing_with_close_friends\") \\\n",
        "                                      .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"playing_with_close_friends\"))\n",
        "\n",
        "# 9. Friend leaving events\n",
        "friend_leaving = df_events.filter(F.col(\"event_type\") == \"friend_leaving\") \\\n",
        "                          .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"friend_leaving\"))\n",
        "\n",
        "# 10. Total in-app purchases\n",
        "total_in_app_purchases = df_events.filter(F.col(\"event_type\") == \"in_app_purchase\") \\\n",
        "                                  .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"total_in_app_purchases\"))\n",
        "\n",
        "# 11. Click events\n",
        "clicks_events = df_events.filter(F.col(\"event_type\") == \"click\") \\\n",
        "                         .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"clicks_events\"))\n",
        "\n",
        "# 12. Seasonality features: counts of sessions during morning, evening, and weekends.\n",
        "df_sessions = df_sessions.withColumn(\"hour\", F.hour(\"event_time\"))\n",
        "df_sessions = df_sessions.withColumn(\"day_of_week\", F.date_format(\"event_time\", \"E\"))\n",
        "morning_sessions = df_sessions.filter((F.col(\"hour\") >= 5) & (F.col(\"hour\") < 12)) \\\n",
        "                              .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"morning_sessions\"))\n",
        "evening_sessions = df_sessions.filter((F.col(\"hour\") >= 18) & (F.col(\"hour\") < 24)) \\\n",
        "                              .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"evening_sessions\"))\n",
        "weekend_sessions = df_sessions.filter(F.col(\"day_of_week\").isin(\"Sat\", \"Sun\")) \\\n",
        "                              .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"weekend_sessions\"))\n",
        "\n",
        "# 13. Number of tutorial completions\n",
        "tutorial_completions = df_events.filter(F.col(\"event_type\") == \"tutorial_completion\") \\\n",
        "                                .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"n_tutorial_completions\"))\n",
        "\n",
        "# 14. Level in game (e.g., maximum level reached via level_up events)\n",
        "level_in_game = df_events.filter(F.col(\"event_type\") == \"level_up\") \\\n",
        "                         .groupBy(\"user_id\").agg(F.max(\"level\").alias(\"level_in_game\"))\n",
        "\n",
        "# 15. Special points (sum over events carrying a 'points' value for special_points events)\n",
        "special_points = df_events.filter(F.col(\"event_type\") == \"special_points\") \\\n",
        "                          .groupBy(\"user_id\").agg(F.sum(\"points\").alias(\"special_points\"))\n",
        "\n",
        "# 16. Special gifts count\n",
        "special_gifts = df_events.filter(F.col(\"event_type\") == \"special_gift\") \\\n",
        "                         .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"special_gifts\"))\n",
        "\n",
        "# 17. Achievements count\n",
        "achievements = df_events.filter(F.col(\"event_type\") == \"achievement\") \\\n",
        "                        .groupBy(\"user_id\").agg(F.count(\"*\").alias(\"achievements\"))\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Join All Features Together\n",
        "# -----------------------------------------------------------------------------\n",
        "\n",
        "# List of DataFrames to join on 'user_id'\n",
        "dfs = [\n",
        "    df_users,\n",
        "    avg_sessions_per_day,\n",
        "    avg_sessions_per_week,\n",
        "    session_length_stats,\n",
        "    last_session.select(\"user_id\", \"time_since_last_session\"),\n",
        "    social_interactions,\n",
        "    playing_with_friends,\n",
        "    playing_with_close_friends,\n",
        "    friend_leaving,\n",
        "    avg_time_between_sessions,\n",
        "    total_in_app_purchases,\n",
        "    clicks_events,\n",
        "    morning_sessions,\n",
        "    evening_sessions,\n",
        "    weekend_sessions,\n",
        "    tutorial_completions,\n",
        "    level_in_game,\n",
        "    special_points,\n",
        "    special_gifts,\n",
        "    achievements\n",
        "]\n",
        "\n",
        "def join_dfs(df1: DataFrame, df2: DataFrame) -> DataFrame:\n",
        "    return df1.join(df2, on=\"user_id\", how=\"left\")\n",
        "\n",
        "final_features = reduce(join_dfs, dfs)\n",
        "\n",
        "# Display the final features DataFrame\n",
        "final_features.orderBy(\"user_id\").show(truncate=False)\n"
      ],
      "metadata": {
        "id": "KasdT8j2F57f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}